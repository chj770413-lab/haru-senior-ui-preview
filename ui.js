/* -----------------------------------------------------------
   1) Whisper API + ê¸°ê¸°ë³„ ìë™ ìŒì„± ì¸ì‹ ì—”ì§„
----------------------------------------------------------- */

// Whisper API URL
const WHISPER_API_URL =
  "https://harudonghaeng-ai-proxy.vercel.app/api/whisper";


  /* ===============================
   ìŒì„± â†’ í…ìŠ¤íŠ¸ ìŠ¤ë§ˆíŠ¸ ì¸ì‹ (ìµœì¢…)
   =============================== */
function startSmartSTT(targetInputId) {
  const status = document.getElementById("voice-status");
  if (status) status.innerText = "ğŸ™ï¸ ë“£ê³  ìˆì–´ìš”â€¦ ë§ì”€í•´ ì£¼ì„¸ìš”";

  // ğŸ”‘ iOS Safari íŒë³„ (í•µì‹¬)
  const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);

  if (isIOS) {
    // âœ… ì•„ì´í°: Whisper (MediaRecorder)
    startWhisperIOS(targetInputId);
  } else {
    // âœ… ë§¥ë¶ / ì•ˆë“œë¡œì´ë“œ: Web Speech API
    startWebSTT(targetInputId);
  }
}

/* ===============================
   ë§¥ë¶ / ì•ˆë“œë¡œì´ë“œ (Chrome)
   Web Speech API
   =============================== */
function startWebSTT(targetInputId) {
  const inputBox = document.getElementById(targetInputId);
  if (!inputBox) return;

  const SpeechRecognition =
    window.SpeechRecognition || window.webkitSpeechRecognition;

  if (!SpeechRecognition) {
    alert("ì´ ê¸°ê¸°ì—ì„œëŠ” ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
    return;
  }

  const recognition = new SpeechRecognition();
  recognition.lang = "ko-KR";

  recognition.onresult = (event) => {
    inputBox.value = event.results[0][0].transcript;

    const status = document.getElementById("voice-status");
    if (status) status.innerText = "ì¸ì‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤";
  };

  recognition.onerror = () => {
    const status = document.getElementById("voice-status");
    if (status) status.innerText = "ë‹¤ì‹œ í•œ ë²ˆ ëˆŒëŸ¬ì£¼ì„¸ìš” ğŸ™‚";
  };

  recognition.onend = () => {
    const status = document.getElementById("voice-status");
    if (status) status.innerText = "";
  };

  recognition.start();
}

/* ===============================
   ì•„ì´í° Safari ì „ìš© Whisper
   =============================== */
async function startWhisperIOS(targetInputId) {
  const inputBox = document.getElementById(targetInputId);

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

    const mediaRecorder = new MediaRecorder(stream, {
      mimeType: "audio/mp4" // ğŸ”‘ iOS í•„ìˆ˜
    });

    let chunks = [];

    mediaRecorder.ondataavailable = (e) => chunks.push(e.data);

    mediaRecorder.onstop = async () => {
  const audioBlob = new Blob(chunks, { type: "audio/mp4" });
  chunks = []; // âœ… ì—¬ê¸°ì„œ ë¹„ì›Œì•¼ í•¨
  stream.getTracks().forEach(track => track.stop()); // âœ… ê·¸ ë‹¤ìŒ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ

  if (audioBlob.size < 500) {
    alert("ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.");
    return;
  }

  const formData = new FormData();
  formData.append("audio", audioBlob, "audio.mp4");

  try {
    const response = await fetch(WHISPER_API_URL, {
      method: "POST",
      body: formData,
    });

    const data = await response.json();
    if (data.text) inputBox.value = data.text;

    const status = document.getElementById("voice-status");
    if (status) status.innerText = "";
  } catch (e) {
    alert("Whisper í†µì‹  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
  }
};

    // ì‹œë‹ˆì–´ UX ê¸°ì¤€ 6ì´ˆ
    setTimeout(() => mediaRecorder.stop(), 6000);

  } catch (err) {
    alert("ì•„ì´í°ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.");
  }
}


/* -----------------------------------------------------------
   2) Whisper Fallback (ëª¨ë“  ê¸°ê¸° ì§€ì›)
----------------------------------------------------------- */

async function startWhisperFallback(targetInputId) {
  const inputBox = document.getElementById(targetInputId);

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const audioContext = new AudioContext();
    const source = audioContext.createMediaStreamSource(stream);
    const processor = audioContext.createScriptProcessor(4096, 1, 1);

    let pcmData = [];

    alert("ğŸ¤ ë§ì”€í•˜ì„¸ìš”. 6ì´ˆ í›„ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.");

    source.connect(processor);
    processor.connect(audioContext.destination);

    processor.onaudioprocess = (event) => {
      const input = event.inputBuffer.getChannelData(0);
      pcmData.push(new Float32Array(input));
    };

    setTimeout(() => {
      processor.disconnect();
      source.disconnect();
      audioContext.close();
      stream.getTracks().forEach(track => track.stop());

      // WAV íŒŒì¼ ìƒì„±
      const wavBuffer = encodeWAV(pcmData, audioContext.sampleRate);
      const audioBlob = new Blob([wavBuffer], { type: "audio/wav" });

      if (audioBlob.size < 500) {
        alert("ë…¹ìŒ ë°ì´í„°ê°€ ë¹„ì–´ ìˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
        return;
      }

      const formData = new FormData();
      formData.append("audio", audioBlob, "audio.wav");

      // Whisperë¡œ ì „ì†¡
      fetch(WHISPER_API_URL, {
        method: "POST",
        body: formData,
      })
        .then((res) => res.json())
        .then((data) => {
          if (data.text) inputBox.value = data.text;
          else alert("Whisper ì¸ì‹ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
        })
        .catch(() => alert("Whisper í†µì‹  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
    }, 6000);

  } catch (err) {
    alert("ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
  }
}

// WAV ì¸ì½”ë” í•¨ìˆ˜
function encodeWAV(pcmData, sampleRate) {
  const bytesPerSample = 2;
  const numChannels = 1;

  let totalLength = pcmData.reduce((acc, cur) => acc + cur.length, 0);
  const buffer = new ArrayBuffer(44 + totalLength * bytesPerSample);
  const view = new DataView(buffer);

  let offset = 0;

  // WAV í—¤ë” ì‘ì„±
  function writeString(str) {
    for (let i = 0; i < str.length; i++) {
      view.setUint8(offset++, str.charCodeAt(i));
    }
  }

  writeString("RIFF");
  view.setUint32(offset, 36 + totalLength * bytesPerSample, true); offset += 4;
  writeString("WAVE");
  writeString("fmt ");
  view.setUint32(offset, 16, true); offset += 4;
  view.setUint16(offset, 1, true); offset += 2;
  view.setUint16(offset, numChannels, true); offset += 2;
  view.setUint32(offset, sampleRate, true); offset += 4;
  view.setUint32(offset, sampleRate * numChannels * bytesPerSample, true); offset += 4;
  view.setUint16(offset, numChannels * bytesPerSample, true); offset += 2;
  view.setUint16(offset, bytesPerSample * 8, true); offset += 2;
  writeString("data");
  view.setUint32(offset, totalLength * bytesPerSample, true); offset += 4;

  // PCM ë°ì´í„° ì‘ì„±
  pcmData.forEach(chunk => {
    for (let i = 0; i < chunk.length; i++) {
      const sample = Math.max(-1, Math.min(1, chunk[i]));
      view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
      offset += 2;
    }
  });

  return buffer;
}


/* -----------------------------------------------------------
   3) TTS (í…ìŠ¤íŠ¸ â†’ ìŒì„±)
----------------------------------------------------------- */

function speak(text) {
  const msg = new SpeechSynthesisUtterance(text);
  msg.lang = "ko-KR";
  speechSynthesis.speak(msg);
}

/* -----------------------------------------------------------
   4) UI í™”ë©´ ì „í™˜ ì²˜ë¦¬
----------------------------------------------------------- */

function clearScreen() {
  document.getElementById("screen").innerHTML = "";
}

function show(type) {
  const screen = document.getElementById("screen");

  if (type === "med") {
    screen.innerHTML = `
      <div class="screen-box">
        <h3>ë³µì•½ ì²´í¬í•˜ê¸°</h3>
        <div class="screen-buttons">
          <button class="sub-btn" onclick="finish('ì•„ì¹¨ ë³µì•½ ì™„ë£Œ')">ì•„ì¹¨ ë³µì•½</button>
          <button class="sub-btn" onclick="finish('ì €ë… ë³µì•½ ì™„ë£Œ')">ì €ë… ë³µì•½</button>
        </div>
      </div>`;
  }

  if (type === "mood") {
    screen.innerHTML = `
      <div class="screen-box">
        <h3>ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë– ì„¸ìš”?</h3>
        <div class="screen-buttons">
          <button class="sub-btn" onclick="finish('ì¢‹ìŒ ê¸°ë¡ë¨')">ğŸ™‚ ì¢‹ìŒ</button>
          <button class="sub-btn" onclick="finish('ë³´í†µ ê¸°ë¡ë¨')">ğŸ˜ ë³´í†µ</button>
          <button class="sub-btn" onclick="finish('ë‚˜ì¨ ê¸°ë¡ë¨')">ğŸ™ ë‚˜ì¨</button>
        </div>
      </div>`;
  }

  if (type === "health") {
    screen.innerHTML = `
      <div class="screen-box">
        <h3>ê±´ê°• ìƒíƒœ ê¸°ë¡í•˜ê¸°</h3>
        <div class="screen-buttons">
          <button class="sub-btn" onclick="finish('ìƒíƒœ: ì–‘í˜¸')">ì–‘í˜¸</button>
          <button class="sub-btn" onclick="finish('ìƒíƒœ: ì£¼ì˜ í•„ìš”')">ì£¼ì˜ í•„ìš”</button>
          <button class="sub-btn" onclick="finish('ìƒíƒœ: ì¢‹ì§€ ì•ŠìŒ')">ì¢‹ì§€ ì•ŠìŒ</button>
        </div>
      </div>`;
  }

  if (type === "ai") {
    screen.innerHTML = `
      <div class="screen-box">
        <h3>í•˜ë£¨ë™í–‰ ê±´ê°• ë„ìš°ë¯¸</h3>

        <textarea 
          id="aiInput"
          class="input-area"
          placeholder="ë§í•˜ê¸° ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ë§ì”€í•´ì£¼ì„¸ìš”."
          style="width: 100%; height: 80px; margin-top: 8px; font-size: 16px;">
        </textarea>

        <div class="screen-buttons" style="margin-top:12px;">
          <button class="sub-btn" onclick="startSmartSTT('aiInput')">ğŸ¤ ë§í•˜ê¸°</button>
          <button class="sub-btn" onclick="sendToAI()">AIì—ê²Œ ë³´ë‚´ê¸°</button>
        </div>
<p id="voice-status" style="margin-top:8px;color:#666;font-size:14px;"></p>

        <div id="aiResponse" class="ai-response-box"
          style="margin-top:14px; font-size:17px; line-height:1.4;"></div>
      </div>`;
  }
}

function finish(msg) {
  const screen = document.getElementById("screen");

  screen.innerHTML = `
    <div class="screen-box">
      <h3>
        ê¸°ë¡ ì™„ë£Œ
        <img src="img/check-green.svg" class="check-icon" />
      </h3>
      <p class="check-message">${msg}</p>
    </div>`;

  setTimeout(() => clearScreen(), 1500);
}

/* -----------------------------------------------------------
   5) AI ì‘ë‹µ ì²˜ë¦¬ (Aë‹¨ê³„: ì§ì „ ì§ˆë¬¸ 1ê°œ ê¸°ì–µ)
----------------------------------------------------------- */

let lastUserMessage = null; // ğŸ‘ˆ íŒŒì¼ ìƒë‹¨ ë˜ëŠ” sendToAI ìœ„ì— 1ë²ˆë§Œ ì„ ì–¸

async function sendToAI() {
  const text = document.getElementById("aiInput").value.trim();
  if (!text) return;

  const resBox = document.getElementById("aiResponse");
  resBox.innerHTML = "â³ ë‹µë³€ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...";

  try {
    const response = await fetch(
      "https://harudonghaeng-ai-proxy.vercel.app/api/chat",
      {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          message: text,
          lastMessage: lastUserMessage, // ğŸ‘ˆ ì§ì „ ì§ˆë¬¸ ì „ë‹¬
        }),
      }
    );

    const data = await response.json();
    const reply = data.reply || "ì ì‹œ í›„ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.";

    resBox.innerHTML = reply;
    speak(reply); // ğŸ”Š AI ìŒì„± ì‘ë‹µ

    // ğŸ‘‡ ì—¬ê¸°ì„œ ë§ˆì§€ë§‰ ì§ˆë¬¸ ì €ì¥ (ë‹¤ìŒ ì§ˆë¬¸ìš©)
    lastUserMessage = text;

  } catch (err) {
    resBox.innerHTML = "ì ì‹œ ì‘ë‹µì´ ëŠ¦ì–´ì§€ê³  ìˆì–´ìš”.<br>ì¡°ê¸ˆ í›„ì— ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ ì£¼ì„¸ìš”.";
}
  }
window.onload = () => {
  show("ai");
};

